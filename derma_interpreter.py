# -*- coding: utf-8 -*-
"""derma_interpreter.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1pIVf7sH8fC1hdOgahcCQVv8UzyZD1T9I
"""

!pip install tflite_runtime
from tflite_runtime.interpreter import Interpreter 
from PIL import Image
import numpy as np
import time

data_folder = "/content/drive/MyDrive/Model/"

model_path = data_folder + "derma_final_model"
label_path = data_folder + "Labels.txt"

interpreter = Interpreter(model_path)
print("Model Loaded Successfully.")

interpreter.allocate_tensors()
_, height, width, _ = interpreter.get_input_details()[0]['shape']
print("Image Shape (",width,",", height,")")

# Load an image to be classified.
image = Image.open(data_folder + "test1.jpg").resize((width, height))

def load_labels(inferred): # Read the labels from the text file as a Python list.
  with open(inferred, 'r') as f:
    return [line.strip() for i, line in enumerate(f.readlines())]

def set_input_tensor(interpreter, image):
  tensor_index = interpreter.get_input_details()[0]['index']
  input_tensor = interpreter.tensor(tensor_index)()[0]
  input_tensor[:, :] = image

def classify_image(interpreter, image, top_k=1):
  set_input_tensor(interpreter, image)

  interpreter.invoke()
  output_details = interpreter.get_output_details()[0]
  output = np.squeeze(interpreter.get_tensor(output_details['index']))

  scale, zero_point = output_details['quantization']
  output = scale * (output - zero_point)

  ordered = np.argpartition(-output, 1)
  return [(i, output[i]) for i in ordered[:top_k]][0]

# Classify the image.
time1 = time.time() #clocking time checkpoint 1
label_id, prob = classify_image(interpreter, image)
time2 = time.time() #clocking time checkpoint 2
classification_time = np.round(time2-time1, 3) # calculating time
print("Classificaiton Time =", classification_time, "seconds.")

# Read class labels.
labels = load_labels(data_folder + "Labels.txt")

# Return the classification label of the image.
classification_label = labels[label_id]
print("Image Label is:", classification_label, "with Accuracy:", np.round(prob*100, 2), "%.")