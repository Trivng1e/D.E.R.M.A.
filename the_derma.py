# -*- coding: utf-8 -*-
"""THE DERMA.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/10a_yIwpTDDMjFHsR6McwenldnuAnYMeP
"""

import matplotlib.pyplot as plt
import numpy as np
import PIL
import tensorflow as tf

import os
os.environ["TF_CPP_MIN_LOG_LEVEL"] = "2"

from tensorflow import keras
from keras import layers, models
from keras.preprocessing.image import ImageDataGenerator
from keras.models import Sequential

img_width = 256
img_height = 256
batch_size = 128

train_images = tf.keras.preprocessing.image_dataset_from_directory(
    '/content/drive/MyDrive/DERMNET/Train/',
    labels='inferred',
    label_mode = "categorical", 
    color_mode='rgb',
    batch_size= batch_size,
    image_size=(img_height,img_width),
    shuffle=True,
    seed=123,
)

test_images = tf.keras.preprocessing.image_dataset_from_directory(
    '/content/drive/MyDrive/DERMNET/Test/',
    labels="inferred",
    label_mode = "categorical", 
    color_mode="rgb",
    batch_size=batch_size,
    image_size=(img_height,img_width),
    shuffle=True,
    seed=123,
)

#for image_batch, labels_batch in train_images:
 # print(image_batch.shape)
  #print(labels_batch.shape)
  #break

#for image_batch, labels_batch in test_images:
 # print(image_batch.shape)
  #print(labels_batch.shape)
  #break

AUTOTUNE = tf.data.AUTOTUNE

train_images = train_images.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)
test_images = test_images.cache().prefetch(buffer_size=AUTOTUNE)

data_augmentation = keras.Sequential(
  [
    layers.RandomFlip("horizontal",
                      input_shape=(img_height,
                                  img_width,
                                  3)),
    layers.RandomRotation(0.1),
    layers.RandomZoom(0.1),
  ]
)

model = models.Sequential()
model.add(keras.Input(shape = (256,256, 3)))
model.add(layers.Conv2D(32, (3, 3), activation='relu'))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(64, (3, 3), activation='relu'))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(64, (3, 3), activation='relu'))
model.add(layers.Flatten())
model.add(layers.Dense(64, activation='relu'))
model.add(layers.Dense(3))

model.summary()

data_augmentation = keras.Sequential(
  [
    layers.RandomFlip("horizontal",
                      input_shape=(img_height,
                                  img_width,
                                  3)),
    layers.RandomRotation(0.1),
    layers.RandomZoom(0.1),
  ]
)

model.compile(optimizer='adam',
              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])

history = model.fit(
    train_images, 
    epochs = 20, 
    batch_size = 128, 
    validation_data = test_images
    )

plt.plot(history.history['accuracy'], label='accuracy')
plt.plot(history.history['val_accuracy'], label = 'val_accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.ylim([0.5, 1])
plt.legend(loc='upper left')

test_loss, test_acc = model.evaluate(test_images, verbose=2)